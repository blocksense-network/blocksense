// SPDX-License-Identifier: MIT
pragma solidity ^0.8.24;

<%_
let name = fields.name.charAt(0).toLowerCase() + fields.name.slice(1);
let containsDynamicData = false;

const expandFields = (values) => {
  const expandedFields = values.map((field) => {
    const isDynamic = field.type === 'bytes' || field.type === 'string' || field.type.includes('[]');
    let data;
    if (isDynamic) {
      data = field;
    } else if (field.type.includes('[')) {
      // This is an array field (potentially multi-dimensional)
      const baseType = field.type.split('[')[0];
      const dimensions = field.type.match(/\[(\d*)\]/g);
      data = expandArray(baseType, dimensions, field);
    } else if (field.type === 'tuple') {
      // This is a tuple field
      data = expandFields(field.components);
    } else {
      // This is not an array field, add it as is
      data = field;
    }    return JSON.parse(JSON.stringify(data));
  });

  return expandedFields;
}

const expandArray = (baseType, dimensions, field) => {
  if (dimensions.length === 0) {
    if (baseType === 'tuple') {
      return expandFields(field.components);
    } else {
      return {
        name: field.name,
        type: baseType,
        size: field.size,
      };
    }
  }

  const currentDimension = dimensions[dimensions.length-1];
  const size = currentDimension.match(/\[(\d*)\]/)[1];
  const arraySize = size ? parseInt(size) : 0;

  const result = [];
  for (let i = 0; i < arraySize || arraySize === 0; i++) {
    result.push(expandArray(baseType, dimensions.slice(0, dimensions.length-1), field));
  }

  return result;
}

function organizeFieldsIntoStructs(values) {
  let structs = [];
  let mainStruct = { name: fields.name, fields: [] };

  function processField(field, parentStruct) {
    if (field.type.includes('tuple')) {
      let newStruct = {
        name: field.name.charAt(0).toUpperCase() + field.name.slice(1),
        fields: []
      };
      if (field.components) {
        field.components.forEach(component => processField(component, newStruct));
      }
      structs.push(newStruct);

      let arrayDimensions = field.type.match(/(\[\d*\])+$/);
      if (arrayDimensions) {
        parentStruct.fields.push({ name: field.name, type: `${newStruct.name}${arrayDimensions[0]}` });
      } else {
        parentStruct.fields.push({ name: field.name, type: newStruct.name });
      }
    } else {
      parentStruct.fields.push({ name: field.name, type: field.type });
    }
  }

  values.forEach(field => processField(field, mainStruct));
  structs.unshift(mainStruct);

  return structs;
}
const organizedStructs = organizeFieldsIntoStructs(fields.values);

let prevSizeSum = 0;
function processFields(fields) {
  fields.forEach((field, index) => {
    if (Array.isArray(field)) {
      // If the field is an array, recursively process its elements
      field = processFields(field);
    } else {
      field.shift = 0;
      const isBytes = field.type.startsWith('bytes') && field.type !== 'bytes' && !field.type.endsWith('[]');
      const isDynamic = field.type === 'bytes' || field.type === 'string' || field.type.endsWith('[]');
      let fieldSize = field.size;
      // Handle bytes fields
      if (isBytes) {
        // Handle bytesNum
        if (prevSizeSum + fieldSize < 256) {
          field.shift = -prevSizeSum;
          prevSizeSum += fieldSize;
        } else {
          prevSizeSum = 0;
        }
      } else if (!isDynamic) {
        // Handle non-bytes fields
        if (prevSizeSum + fieldSize >= 256) {
          prevSizeSum = 0;
        }

        field.shift = 256 - prevSizeSum - fieldSize;
        prevSizeSum += fieldSize;
      } else {
        // Handle dynamic data
        field.isDynamic = true;
        containsDynamicData = true;
        prevSizeSum = 0;
      }

      if (!!!fieldSize) {
        field.size = 0;
      }
    }
  });

  return fields;
}

const expandedFields = processFields(expandFields(fields.values));
let wordOffset = 32;
let bitOffset = 0;
let prevSize = 0;
let shouldUpdate = false;
let shift = false;
function generateDecoderLines(expandedFields, name, startIndex = 0, indentation = '') {
  const lines = [];
  let index = startIndex;
  let location = name;

  for (let i = 0; i < expandedFields.length; i++) {
    const field = expandedFields[i];

    bitOffset += Array.isArray(field) || field.isDynamic ? 0 : field.size;

    if (!Array.isArray(field) && prevSize + field.size >= 256) {
      wordOffset += prevSize / 8;
      bitOffset = field.isDynamic ? 0 : field.size;
      shouldUpdate = true;
      prevSize = 0;
    }

    if (shouldUpdate && (wordOffset > 32 || shift)) {      lines.push('');
      lines.push(`// Offset data with ${wordOffset} bytes`);
      lines.push(`memData := mload(add(data, ${shift ? `add(shift, ${wordOffset})` : wordOffset}))`);
      lines.push('');
      shouldUpdate = false;
    }

    if (Array.isArray(field)) {
      const innerName = name + '_' + index;
      lines.push('');
      lines.push('{');
      lines.push(`  // Get address of field at slot ${index + 1} of ${name}`);
      lines.push(`  let ${innerName} := mload(${index ? `add(${name}, ${index * 0x20})` : name})`);
      const innerLines = generateDecoderLines(field, innerName, 0, '  ');
      lines.push(...innerLines);
      lines.push('}');
    } else if (!field.isDynamic) {
      prevSize += field.size;
      lines.push(`// Store the next ${field.size} bytes of memData at slot ${index + 1} of ${location}`);
      lines.push(`mstore(${index ? `add(${location}, ${index * 0x20})` : location}, ${field.shift == 0 ? 'memData' : field.shift < 0 ? `shl(${Math.abs(field.shift)}, memData)` : field.size < 256 ? `and(shr(${field.shift}, memData), ${'0x' + 'F'.repeat(field.size / 4)})` : `shr(${field.shift}, memData)`})`);
    } else {
      lines.push('');
      lines.push(`shift := add(shift, ${wordOffset + prevSize / 8 + 4})`);
      shift = true;

      const isBytes = field.type.startsWith('bytes') && field.type !== 'bytes';

      lines.push(`{`);
      lines.push(`  let ${field.name} := mload(0x40)`);
      lines.push(`  let size := and(shr(${256 - bitOffset - 32}, memData), 0xFFFFFFFF)`);
      lines.push(`  mstore(${index ? `add(${location}, ${index * 0x20})` : location}, ${field.name})`);
      lines.push(`  mstore(0x40, add(${field.name}, mul(add(size, 1), 32)))`);
      lines.push(`  mstore(${field.name}, size)`);
      if (field.type === 'bytes' || field.type === 'string') {
        lines.push(`  let i := 32`);
        lines.push(`  for {`);
        lines.push(`  } lt(i, size) {`);
        lines.push(`    i := add(i, 32)`);
        lines.push(`    shift := add(shift, 32)`);
        lines.push(`  } {`);
        lines.push(`    memData := mload(add(data, shift))`);
        lines.push(`    mstore(add(${field.name}, i), memData)`);
        lines.push(`  }`);
        lines.push(`  memData := mload(add(data, shift))`);
        lines.push(`  mstore(add(${field.name}, i), memData)`);
        lines.push(`  shift := add(shift, mod(size, 32))`)
        lines.push(`  memData := mload(add(data, shift))`)
      } else {
        lines.push(`  let prevSizeSum := 0`);
        if (isBytes) {
          lines.push(`  let offset := 32`);
        } else {
          lines.push(`  let offset := ${field.size + 32}`);
        }
        lines.push(`  for {`);
        lines.push(`    let i := 0`);
        lines.push(`  } lt(i, size) {`);
        lines.push(`    i := add(i, 1)`);
        lines.push(`    offset := add(offset, ${field.size})`);
        lines.push(`    prevSizeSum := add(prevSizeSum, ${field.size})`);
        lines.push(`  } {`);
        if (isBytes) {
          lines.push(`    if gt(add(offset, ${field.size}), 256) {`);
        } else {
          lines.push(`    if gt(offset, 256) {`);
        }
        lines.push(`      shift := add(shift, div(prevSizeSum, 8))`);
        lines.push(`      memData := mload(add(data, shift))`);
        if (isBytes) {
          lines.push(`      offset := 0`);
        } else {
          lines.push(`      offset := ${field.size}`);
        }
        lines.push(`      prevSizeSum := 0`);
        lines.push(`    }`);
        lines.push(`    mstore(`);
        lines.push(`      add(${field.name}, mul(0x20, add(i, 1))),`);
        if (isBytes) {
          lines.push(`      shl(offset, memData)`);
        } else {
          lines.push(`      and(shr(sub(256, offset), memData), ${'0x' + 'F'.repeat(field.size / 4)})`);
        }
        lines.push(`    )`);
        lines.push(`  }`);
        if (isBytes) {
          lines.push(`    switch gt(add(offset, ${field.size}), 256)`);
        } else {
          lines.push(`    switch gt(offset, 256)`);
        }
        lines.push(`  case 1 {`);
        lines.push(`    shift := add(shift, div(prevSizeSum, 8))`);
        lines.push(`  }`);
        lines.push(`  default {`);
        lines.push(`    shift := add(shift, div(sub(offset, ${field.size + 32}), 8))`);
        lines.push(`  }`);
        lines.push(`  memData := mload(add(data, shift))`);
      }
      lines.push(`}`);
      wordOffset = 0;
      prevSize = 0;
      bitOffset = 0;
    }
    index++;
  }

  return lines.map(line => line !== '' ? indentation + line : line);
}-%>

/// @notice Decoder for stored packed sports data
library Decoder {
  /// @notice User defined struct
  /// @dev Using structs avoids hitting the EVM stack limit
<%= organizedStructs.map((struct) => {
  return `  struct ${struct.name} {
  ${struct.fields.map((fields) => `  ${fields.type} ${fields.name};`).join('\n  ')}
  }`
}).join('\n\n') %>

  function decode(
    bytes memory data
  ) external pure returns (<%= fields.name %> memory <%= name %>) {
    assembly {
      // First 32 bytes are the length of the data
      let memData := mload(add(data, 32))
      <%= containsDynamicData ? 'let shift := 0' : '' %>
      <%= generateDecoderLines(expandedFields, name).join('\n      ') %>
    }
  }
}
