// SPDX-License-Identifier: MIT
pragma solidity ^0.8.24;

<%_
let name = fields.name.charAt(0).toLowerCase() + fields.name.slice(1)

const expandFields = (values) => {
  const expandedFields = values.map((field) => {
    let data;
    if (field.type.endsWith(']')) {
      // This is an array field
      const baseType = field.type.split('[')[0];
      const arraySize = field.type.match(/\[(\d*)\]/)[1] || field.length;
      data = [];
      for (let i = 0; i < parseInt(arraySize); i++) {
        if (baseType === 'tuple') {
          // Handle tuple array
          data.push(expandFields(field.components));
        } else {
          data.push({
            type: baseType,
            size: field.size,
          });
        }
      }
    } else if (field.type === 'tuple') {
      // This is a tuple field
      data = expandFields(field.components);
    } else {
      // This is not an array field, add it as is
      data = field;
    }
    return JSON.parse(JSON.stringify(data));
  });

  return expandedFields;
}

function organizeFieldsIntoStructs(values) {
  let structs = [];
  let mainStruct = { name: fields.name, fields: [] };

  function processField(field, parentStruct) {
    if (field.type === 'tuple' || (field.type.endsWith(']') && field.components)) {
      let newStruct = {
        name: field.name.charAt(0).toUpperCase() + field.name.slice(1),
        fields: []
      };
      if (field.components) {
        field.components.forEach(component => processField(component, newStruct));
      }
      structs.push(newStruct);
      if (field.type.endsWith(']')) {
        parentStruct.fields.push({ name: field.name, type: `${newStruct.name}[${field.type.split('[')[1]}` });
      } else {
        parentStruct.fields.push({ name: field.name, type: newStruct.name });
      }
    } else if (field.type.endsWith('[]')) {
      let arrayType = field.type.split('[')[0];
      parentStruct.fields.push({ name: field.name, type: `${arrayType}[]` });
    } else {
      parentStruct.fields.push({ name: field.name, type: field.type });
    }
  }

  values.forEach(field => processField(field, mainStruct));
  structs.unshift(mainStruct);

  return structs;
}
const organizedStructs = organizeFieldsIntoStructs(fields.values);

let prevSizeSum = 0;
function processFields(fields) {
  fields.forEach((field, index) => {
    if (Array.isArray(field)) {
      // If the field is an array, recursively process its elements
      field = processFields(field);
    } else {
      field.shift = 0;
      const isBytes = field.type.startsWith('bytes');
      const isBytesMemory = field.type === 'bytes';
      let fieldSize = field.size;
      // Handle bytes fields
      if (isBytes) {
        if (prevSizeSum + fieldSize < 256) {
          // Handle bytesNum (not array or bytes memory)
          if (!isBytesMemory) {
            field.shift = -prevSizeSum;
          }
          prevSizeSum += fieldSize;
        } else {
          prevSizeSum = 0;
        }
      } else {
        // Handle non-bytes fields
        if (prevSizeSum + fieldSize >= 256) {
          prevSizeSum = 0;
        }

        field.shift = 256 - prevSizeSum - fieldSize;
        prevSizeSum += fieldSize;
      }
    }
  });

  return fields;
}

const expandedFields = processFields(expandFields(fields.values));

let wordOffset = 32;
let bitOffset = 0;
let prevSize = 0;
let shouldUpdate = false;
function generateDecoderLines(expandedFields, name, startIndex = 0) {
  const lines = [];
  let index = startIndex;
  let location = name;

  for (let i = 0; i < expandedFields.length; i++) {
    const field = expandedFields[i];

    bitOffset += Array.isArray(field) ? 0 : field.size;

    if (!Array.isArray(field) && prevSize + field.size >= 256) {
      wordOffset += prevSize / 8;
      bitOffset = field.size;
      shouldUpdate = true;
      prevSize = 0;
    }

    if (shouldUpdate && wordOffset > 32) {
      lines.push('');
      lines.push(`// Offset data with ${wordOffset} bytes`);
      lines.push(`memData := mload(add(data, ${wordOffset}))`);
      lines.push('');
      shouldUpdate = false;
    }

    if (Array.isArray(field)) {
      const innerName = name + '_' + index;
      lines.push('');
      lines.push(`// Get address of field at slot ${index + 1} of ${name}`);
      lines.push(`let ${innerName} := mload(${index ? `add(${name}, ${index * 0x20})` : name})`);
      const innerLines = generateDecoderLines(field, innerName, 0);
      lines.push(...innerLines);
    } else if (field.size <= 256) {
      prevSize += field.size;
      lines.push(`// Store the next ${field.size} bytes of memData at slot ${index + 1} of ${location}`);
      lines.push(`mstore(${index ? `add(${location}, ${index * 0x20})` : location}, ${field.shift == 0 ? 'memData' : field.shift < 0 ? `shl(${Math.abs(field.shift)}, memData)` : field.size < 256 ? `and(shr(${field.shift}, memData), ${'0x' + 'F'.repeat(field.size / 4)})` : `shr(${field.shift}, memData)`})`);
    } else {
      lines.push('// Handle larger types (bytes) here');
    }
    index++;
  }

  return lines;
}-%>

/// @notice Decoder for stored packed sports data
library Decoder {
  /// @notice User defined struct
  /// @dev Using structs avoids hitting the EVM stack limit
<%= organizedStructs.map((struct) => {
  return `  struct ${struct.name} {
  ${struct.fields.map((fields) => `  ${fields.type} ${fields.name};`).join('\n  ')}
  }`
}).join('\n\n') %>

  function decode(
    bytes memory data
  ) external pure returns (<%= fields.name %> memory <%= name %>) {
    assembly {
      // First 32 bytes are the length of the data
      let memData := mload(add(data, 32))

      <%= generateDecoderLines(expandedFields, name).join('\n      ') %>
    }
  }
}
